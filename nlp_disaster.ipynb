{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-disaster.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4aba749098594917b81e99675bc3148b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_24996746069b4a0b90e9758dc1ce0995",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6d6761f994034599afaeae4041dc5a8a",
              "IPY_MODEL_654ebf87651e4f78829f8adf1d575753"
            ]
          }
        },
        "24996746069b4a0b90e9758dc1ce0995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d6761f994034599afaeae4041dc5a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d9927bebbee143d28242ce32072e79d2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3a4827bb36444f7ae65e1563ebef6ac"
          }
        },
        "654ebf87651e4f78829f8adf1d575753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_91631f50ca034e2aa6cd8540bebcf340",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 3.04MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43d6c4a6bb234e8f89a661dc989badbf"
          }
        },
        "d9927bebbee143d28242ce32072e79d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3a4827bb36444f7ae65e1563ebef6ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91631f50ca034e2aa6cd8540bebcf340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43d6c4a6bb234e8f89a661dc989badbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dcdeee9e6b5949a28c3a30990c3f5f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7f6a1cf62f294054a93f7ea7f70bdabe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a64803a4f1245b7b023003bb8351de7",
              "IPY_MODEL_498490669c11429bac15da012800a10f"
            ]
          }
        },
        "7f6a1cf62f294054a93f7ea7f70bdabe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a64803a4f1245b7b023003bb8351de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_97288aa101bc4f859ec4550b6cdbf187",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b982f23c277f41439fd99d8b240224a2"
          }
        },
        "498490669c11429bac15da012800a10f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a9eec430cde34c4b8429be81460adad6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:06&lt;00:00, 71.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5edad1013de42ffac32e8703b00f122"
          }
        },
        "97288aa101bc4f859ec4550b6cdbf187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b982f23c277f41439fd99d8b240224a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9eec430cde34c4b8429be81460adad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5edad1013de42ffac32e8703b00f122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8e8c3cb9e1043479a0f50efee6d0b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1b996cef06e443a2a815cac45b16edca",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_add7100649e94817bc826f9f88541b4b",
              "IPY_MODEL_98ab0422753f4c279d7cdd84569aa1c3"
            ]
          }
        },
        "1b996cef06e443a2a815cac45b16edca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "add7100649e94817bc826f9f88541b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e48b40c960ef4a59b3166e96bbf9cbc1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_924c8b2562f649128bf8b923e323dd88"
          }
        },
        "98ab0422753f4c279d7cdd84569aa1c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b33d8b98c4d14514aac4c28cc1a3c5ae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:05&lt;00:00, 73.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7aaad63c1ef42c79597140cc78a9fd7"
          }
        },
        "e48b40c960ef4a59b3166e96bbf9cbc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "924c8b2562f649128bf8b923e323dd88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b33d8b98c4d14514aac4c28cc1a3c5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7aaad63c1ef42c79597140cc78a9fd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRHbRqDU9BT-",
        "outputId": "0843be35-8655-48ea-b6e6-3ab027f4df53"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTtOO4xO8by2",
        "outputId": "8ca406a5-6bea-4898-82bf-a659256f5997"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv('train.csv')\n",
        "print(train_data.head(5))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id keyword  ...                                               text target\n",
            "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
            "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
            "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
            "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
            "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0DEtcfy81cz"
      },
      "source": [
        "sentences = train_data['text']\n",
        "\n",
        "labels = train_data['target']"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ4TuN3EC5Dm",
        "outputId": "023837d8-b964-4d5b-e3f1-dc882bd7d889"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9-4eUmA-7Mr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375,
          "referenced_widgets": [
            "4aba749098594917b81e99675bc3148b",
            "24996746069b4a0b90e9758dc1ce0995",
            "6d6761f994034599afaeae4041dc5a8a",
            "654ebf87651e4f78829f8adf1d575753",
            "d9927bebbee143d28242ce32072e79d2",
            "d3a4827bb36444f7ae65e1563ebef6ac",
            "91631f50ca034e2aa6cd8540bebcf340",
            "43d6c4a6bb234e8f89a661dc989badbf"
          ]
        },
        "outputId": "11b352e9-0bed-43ea-a474-978128dddd37"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "import numpy as np\n",
        "\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation = True\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4aba749098594917b81e99675bc3148b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
            "Token IDs: tensor([  101,  3458,  9115,  3680,  1132,  1103, 21642,  1104,  1142,   108,\n",
            "         8386,  1318, 18589, 10783,  3048,  1370,  5389,  2707,  1366,  1155,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO1LYR3MBS5F",
        "outputId": "a776111f-a776-4c8d-fd1f-afa595a3bce9"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6,851 training samples\n",
            "  762 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVJ6VULWBlD4"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFT9gRBV9Dja",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dcdeee9e6b5949a28c3a30990c3f5f72",
            "7f6a1cf62f294054a93f7ea7f70bdabe",
            "2a64803a4f1245b7b023003bb8351de7",
            "498490669c11429bac15da012800a10f",
            "97288aa101bc4f859ec4550b6cdbf187",
            "b982f23c277f41439fd99d8b240224a2",
            "a9eec430cde34c4b8429be81460adad6",
            "d5edad1013de42ffac32e8703b00f122",
            "b8e8c3cb9e1043479a0f50efee6d0b74",
            "1b996cef06e443a2a815cac45b16edca",
            "add7100649e94817bc826f9f88541b4b",
            "98ab0422753f4c279d7cdd84569aa1c3",
            "e48b40c960ef4a59b3166e96bbf9cbc1",
            "924c8b2562f649128bf8b923e323dd88",
            "b33d8b98c4d14514aac4c28cc1a3c5ae",
            "d7aaad63c1ef42c79597140cc78a9fd7"
          ]
        },
        "outputId": "7c3c9935-9985-4c90-d5d0-02c8dcedcfeb"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dcdeee9e6b5949a28c3a30990c3f5f72",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8e8c3cb9e1043479a0f50efee6d0b74",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZmuCc819VD8"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkNSzc-59j9Q"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXjJZ6JB9y5s"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWDtECVh95Yg"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrNTMTee96Di",
        "outputId": "c1dc4940-75d3-4021-aaf0-1f0a459bc4ce"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    215.    Elapsed: 0:00:27.\n",
            "  Batch    80  of    215.    Elapsed: 0:00:56.\n",
            "  Batch   120  of    215.    Elapsed: 0:01:25.\n",
            "  Batch   160  of    215.    Elapsed: 0:01:53.\n",
            "  Batch   200  of    215.    Elapsed: 0:02:22.\n",
            "\n",
            "  Average training loss: 0.46\n",
            "  Training epcoh took: 0:02:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.39\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    215.    Elapsed: 0:00:29.\n",
            "  Batch    80  of    215.    Elapsed: 0:00:57.\n",
            "  Batch   120  of    215.    Elapsed: 0:01:25.\n",
            "  Batch   160  of    215.    Elapsed: 0:01:54.\n",
            "  Batch   200  of    215.    Elapsed: 0:02:22.\n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Training epcoh took: 0:02:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.39\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:05:16 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "MSJrefvyCB87",
        "outputId": "bf438476-8090-42bc-d39d-171bb598d93f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.46</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:02:32</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.33</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:02:32</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.46         0.39           0.83       0:02:32         0:00:06\n",
              "2               0.33         0.39           0.83       0:02:32         0:00:06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2k3HI0cLDCm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "22630ece-6c94-4297-daf2-d38233d93b32"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOq_1f1PLfCq",
        "outputId": "6dd10226-be70-40be-f342-e1390c9a3944"
      },
      "source": [
        "# Test Set\n",
        "import pandas as pd\n",
        "\n",
        "test_data = pd.read_csv('test.csv')\n",
        "#print(test_data.head(5))\n",
        "\n",
        "sentences = test_data['text']\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation = True\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "#labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrvFiw9KPQKt",
        "outputId": "2f5f93de-1285-4648-cdad-8c77b021c570"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions = []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  #label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  #true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 3,263 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuCB5BxpPrDU"
      },
      "source": [
        "import torch.nn.functional as nnf\n",
        "pred_classes = []\n",
        "\n",
        "for batch in predictions:\n",
        "  probs = nnf.softmax(torch.from_numpy(batch), dim = -1)\n",
        "  for i in range(probs.shape[0]):\n",
        "    prob = probs[i]\n",
        "    prob_0 = float(prob[0])\n",
        "    prob_1 = float(prob[1])\n",
        "    if prob_1 > prob_0:\n",
        "      pred_classes.append(1)\n",
        "    else:\n",
        "      pred_classes.append(0)\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk5WEsHid5-j",
        "outputId": "4f78c55a-bf4d-4ffa-a892-9a75f9301616"
      },
      "source": [
        "output = {'id': test_data['id'],\n",
        "          'target': pred_classes}\n",
        "\n",
        "pred_output = pd.DataFrame(output)\n",
        "print(pred_output.head(5))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id  target\n",
            "0   0       1\n",
            "1   2       1\n",
            "2   3       1\n",
            "3   9       1\n",
            "4  11       1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1Km9KPkenpr"
      },
      "source": [
        "pred_output.to_csv('nnBertOut.csv', index = False)"
      ],
      "execution_count": 60,
      "outputs": []
    }
  ]
}